{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "10e15a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-recommenders\n",
    "# !pip install -q --upgrade tensorflow-datasets\n",
    "# !pip install -q scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d2cf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n",
    "import sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f67aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4a788a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e89a1",
   "metadata": {},
   "source": [
    "# Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a1718cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_SMALL = \"../EDA_files/ratings_small.parquet\"\n",
    "RECIPES_SMALL = \"../EDA_files/recipes_small.parquet\"\n",
    "INDEX_TO_RECIPE_OBJ = \"../EDA_files/index_to_recipe.obj\"\n",
    "RECIPE_TO_INDEX_OBJ = \"../EDA_files/recipe_to_index.obj\"\n",
    "\n",
    "ING_CLEAN_NO_COMMON = '../cleaned_files/ingredients_clean_without_common_words.obj'\n",
    "KEYWORDS_CLEAN = '../cleaned_files/keywords_cleaned.obj'\n",
    "CATEGORIES_CLEAN = '../cleaned_files/categories_cleaned.obj'\n",
    "NAMES_CLEAN = '../cleaned_files/names_cleaned.obj'\n",
    "\n",
    "RECIPES_DATA = \"../dataset/recipes.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0c03d",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c3d7c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_small = pd.read_parquet(RECIPES_SMALL)\n",
    "ratings_small = pd.read_parquet(RATINGS_SMALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4cdef96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_parquet(RECIPES_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59bcf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ING_CLEAN_NO_COMMON, \"rb\") as input_file:\n",
    "    ingredients_no_common_words = pickle.load(input_file)\n",
    "\n",
    "with open(KEYWORDS_CLEAN, \"rb\") as input_file:\n",
    "    keywords_clean = pickle.load(input_file)\n",
    "\n",
    "with open(CATEGORIES_CLEAN, \"rb\") as input_file:\n",
    "    categories_clean = pickle.load(input_file)\n",
    "    \n",
    "with open(NAMES_CLEAN, \"rb\") as input_file:\n",
    "    names_clean = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "89b6c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_no_common_words.Ingredients = ingredients_no_common_words.Ingredients.map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "546705f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_clean.Keywords = keywords_clean.Keywords.map(lambda x: ' '.join(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c5125535",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_clean = recipes_small.copy()\n",
    "recipes_clean.drop(columns=['Ingredients', 'Keywords', 'RecipeCategory', 'Nutritions'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b440651",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_clean = recipes_clean.merge(ingredients_no_common_words, on='RecipeId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "90b711de",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_clean = recipes_clean.merge(keywords_clean, on='RecipeId')\n",
    "recipes_clean = recipes_clean.merge(categories_clean, on='RecipeId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "805792e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = recipes[['RecipeId', 'Calories', 'FatContent', 'SaturatedFatContent',\n",
    "                                            'CholesterolContent', 'SodiumContent', 'CarbohydrateContent',\n",
    "                                            'FiberContent', 'SugarContent', 'ProteinContent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0dd4f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_clean = recipes_clean.merge(sample, on='RecipeId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc68b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(recipes)\n",
    "del(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "efd9bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_min_20 = sampling.get_rating_with_min_number(ratings_small, 20, col_name='AuthorId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405beec1",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45806056",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3b13ab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1401982 entries, 0 to 1401981\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count    Dtype              \n",
      "---  ------         --------------    -----              \n",
      " 0   RecipeId       1401982 non-null  int32              \n",
      " 1   AuthorId       1401982 non-null  int32              \n",
      " 2   Rating         1401982 non-null  int32              \n",
      " 3   Review         1401982 non-null  object             \n",
      " 4   DateSubmitted  1401982 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int32(3), object(1)\n",
      "memory usage: 37.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e364b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_min_20.AuthorId = author_min_20.AuthorId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "author_min_20.RecipeId = author_min_20.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "acbcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = author_min_20.groupby(['AuthorId', 'RecipeId'])['Rating'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0360d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = {name: np.array(value) for name, value in ratings_dict.items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2d404e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {'AuthorId' : x['AuthorId'], \n",
    "                                 'RecipeId' : x['RecipeId'], \n",
    "                                 'Rating' : float(x['Rating']),})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79a7a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'109470'}\n",
      "{'AuthorId': b'100026', 'Rating': 4.0, 'RecipeId': b'120462'}\n",
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'120553'}\n",
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'120914'}\n",
      "{'AuthorId': b'100026', 'Rating': 4.0, 'RecipeId': b'121855'}\n",
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'12187'}\n",
      "{'AuthorId': b'100026', 'Rating': 4.0, 'RecipeId': b'127106'}\n",
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'128092'}\n",
      "{'AuthorId': b'100026', 'Rating': 4.0, 'RecipeId': b'129908'}\n",
      "{'AuthorId': b'100026', 'Rating': 5.0, 'RecipeId': b'130320'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(10).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aaca6",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c51abfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 522517 entries, 0 to 522516\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count   Dtype              \n",
      "---  ------               --------------   -----              \n",
      " 0   RecipeId             522517 non-null  int64              \n",
      " 1   Name                 522517 non-null  object             \n",
      " 2   AuthorId             522517 non-null  int32              \n",
      " 3   CookTimeInMinutes    522517 non-null  float64            \n",
      " 4   PrepTimeInMinutes    522517 non-null  float64            \n",
      " 5   TotalTimeInMinutes   522517 non-null  float64            \n",
      " 6   DatePublished        522517 non-null  datetime64[ns, UTC]\n",
      " 7   Description          522512 non-null  object             \n",
      " 8   RecipeServings       339606 non-null  float64            \n",
      " 9   RecipeInstructions   522517 non-null  object             \n",
      " 10  Ingredients          522517 non-null  object             \n",
      " 11  Keywords             522517 non-null  object             \n",
      " 12  RecipeCategory       522517 non-null  object             \n",
      " 13  Calories             522517 non-null  float64            \n",
      " 14  FatContent           522517 non-null  float64            \n",
      " 15  SaturatedFatContent  522517 non-null  float64            \n",
      " 16  CholesterolContent   522517 non-null  float64            \n",
      " 17  SodiumContent        522517 non-null  float64            \n",
      " 18  CarbohydrateContent  522517 non-null  float64            \n",
      " 19  FiberContent         522517 non-null  float64            \n",
      " 20  SugarContent         522517 non-null  float64            \n",
      " 21  ProteinContent       522517 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(13), int32(1), int64(1), object(6)\n",
      "memory usage: 89.7+ MB\n"
     ]
    }
   ],
   "source": [
    "recipes_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fcaf2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"RecipeId\", \"Name\", \"Keywords\", \"Ingredients\", \"FatContent\", \"SaturatedFatContent\", \"CholesterolContent\", \"SodiumContent\",\n",
    "           \"CarbohydrateContent\", \"FiberContent\",\"SugarContent\", \"ProteinContent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efba8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items_dict = recipes_clean.groupby(['RecipeId'])[\"Name\", \"Keywords\", \"Ingredients\", \"FatContent\", \"SaturatedFatContent\", \"CholesterolContent\", \"SodiumContent\",\n",
    "#            \"CarbohydrateContent\", \"FiberContent\",\"SugarContent\", \"ProteinContent\"].sum().reset_index()\n",
    "\n",
    "recipes_clean.RecipeId = recipes_clean.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "items_dict = recipes_clean[features]\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2cb50963",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.map(lambda x: x['RecipeId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465c661",
   "metadata": {},
   "source": [
    "## Basic version - just ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dc922f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = author_min_20.shape[0]\n",
    "train_size = int(0.8 * size)\n",
    "test_size = size - train_size\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(size, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.take(train_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e332e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ids = items.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"AuthorId\"])\n",
    "\n",
    "unique_recipe_ids = np.unique(np.concatenate(list(recipe_ids)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "46f420c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_user_ids = [bytes(str(x), 'utf-8') for x in unique_user_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4b9d51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_recipe_ids = [bytes(str(x), 'utf-8') for x in unique_recipe_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61939904",
   "metadata": {},
   "source": [
    "# Implementing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ae685",
   "metadata": {},
   "source": [
    "## Query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1e2f165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "537fb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35bff0e",
   "metadata": {},
   "source": [
    "## Candidate tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "48bfab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_recipe_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_recipe_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0b8c9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "23a0f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeModel(tfrs.Model):\n",
    "    def __init__(self, user_model, recipe_model):\n",
    "        super().__init__()\n",
    "        self.recipe_model: tf.keras.Model = recipe_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "            \n",
    "        metrics = tfrs.metrics.FactorizedTopK(candidates=items.batch(128).map(recipe_model))\n",
    "        task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "            \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        print(features)\n",
    "        user_embeddings = self.user_model(features[\"AuthorId\"])\n",
    "        positive_recipe_embeddings = self.recipe_model(features[\"RecipeId\"])\n",
    "        \n",
    "        return self.task(user_embeddings, positive_recipe_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1468f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecipeModel(user_model, recipe_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c6d31156",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e07f06a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "{'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'RecipeId': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Rating': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}\n",
      "{'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'RecipeId': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Rating': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}\n",
      " 5/89 [>.............................] - ETA: 6:44:04 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 2.4414e-05 - factorized_top_k/top_10_categorical_accuracy: 7.3242e-05 - factorized_top_k/top_50_categorical_accuracy: 3.4180e-04 - factorized_top_k/top_100_categorical_accuracy: 5.3711e-04 - loss: 73818.2719 - regularization_loss: 0.0000e+00 - total_loss: 73818.2719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UYTKOW~1\\AppData\\Local\\Temp/ipykernel_7700/2831010455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\RecSys\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47df4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
