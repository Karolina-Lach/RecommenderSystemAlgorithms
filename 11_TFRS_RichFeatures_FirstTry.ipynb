{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60389781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade83d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n",
    "import sampling\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Flatten   # to flatten the input data\n",
    "from tensorflow.keras.layers import Dense     # for the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa97de",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3614e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_SMALL = \"../Data/EDA_files/ratings_small.parquet\"\n",
    "RECIPES_SMALL = \"../Data/EDA_files/recipes_small.parquet\"\n",
    "\n",
    "ING_CLEAN_NO_COMMON = '../Data/cleaned_files/ingredients_clean_without_common_words.obj'\n",
    "KEYWORDS_CLEAN = '../Data/cleaned_files/keywords_cleaned.obj'\n",
    "CATEGORIES_CLEAN = '../Data/cleaned_files/categories_cleaned.obj'\n",
    "NAMES_CLEAN = '../Data/cleaned_files/names_cleaned.obj'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cfafb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa98504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_small = pd.read_parquet(RECIPES_SMALL)\n",
    "ratings_small = pd.read_parquet(RATINGS_SMALL)\n",
    "\n",
    "with open(ING_CLEAN_NO_COMMON, \"rb\") as input_file:\n",
    "    ingredients = pickle.load(input_file)\n",
    "    \n",
    "with open(CATEGORIES_CLEAN, \"rb\") as input_file:\n",
    "    categories = pickle.load(input_file)\n",
    "    \n",
    "with open(NAMES_CLEAN, \"rb\") as input_file:\n",
    "    names = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3a0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1401982 entries, 0 to 1401981\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count    Dtype              \n",
      "---  ------         --------------    -----              \n",
      " 0   RecipeId       1401982 non-null  int32              \n",
      " 1   AuthorId       1401982 non-null  int32              \n",
      " 2   Rating         1401982 non-null  int32              \n",
      " 3   Review         1401982 non-null  object             \n",
      " 4   DateSubmitted  1401982 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int32(3), object(1)\n",
      "memory usage: 37.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_small.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dc5a3",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0d29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_small[\"Timestamp\"] = ratings_small.DateSubmitted.map(lambda x: int(x.timestamp()))\n",
    "ratings_small.drop(columns=[\"Rating\", \"Review\", \"DateSubmitted\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02782af",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_min_20 = sampling.get_rating_with_min_number(ratings_small, 20, col_name='AuthorId')\n",
    "recipe_min_20 = sampling.get_rating_with_min_number(ratings_small, 10, col_name='RecipeId')\n",
    "\n",
    "ratings_min_20 = author_min_20.merge(recipe_min_20, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ae9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sample = ratings_min_20.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bf20ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            780\n",
       "1           4366\n",
       "2           4807\n",
       "3            810\n",
       "4           5466\n",
       "           ...  \n",
       "441660     49088\n",
       "441661     43023\n",
       "441662     73866\n",
       "441663     26370\n",
       "441664    339905\n",
       "Name: RecipeId, Length: 441665, dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_sample.RecipeId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b70ec",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ab7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset = recipes_small[[\"RecipeId\"]].merge(ingredients, on=\"RecipeId\", how=\"inner\").merge(categories, on=\"RecipeId\",\n",
    "                                                                                                 how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaba39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset[\"Ingredients\"] = recipes_subset[\"Ingredients\"].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ed74d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recipes_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UYTKOW~1\\AppData\\Local\\Temp/ipykernel_8904/1320126525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipes_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"RecipeId\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'recipes_sample' is not defined"
     ]
    }
   ],
   "source": [
    "merged_dataset = ratings_sample.merge(recipes_sample, on=\"RecipeId\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed0f2e",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.AuthorId = merged_dataset.AuthorId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "merged_dataset.RecipeId = merged_dataset.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "\n",
    "ratings_dict = merged_dataset[['AuthorId', 'RecipeId', 'Timestamp', \"Ingredients\", \"RecipeCategory\"]]\n",
    "ratings_dict = {name: np.array(value) for name, value in ratings_dict.items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings_dict)\n",
    "\n",
    "\n",
    "ratings = ratings.map(lambda x: {'AuthorId' : x['AuthorId'], \n",
    "                                 'RecipeId' : x['RecipeId'],\n",
    "                                 'Timestamp' : x['Timestamp'],\n",
    "                                 'Ingredients' : x['Ingredients'], \n",
    "                                 'RecipeCategory': x['RecipeCategory']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d705a15",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730beda7",
   "metadata": {},
   "source": [
    "## Creating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_ids_lookup = tf.keras.layers.StringLookup()\n",
    "# recipe_ids_lookup.adapt(ratings.map(lambda x: x[\"RecipeId\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d35f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Vocabulary: {recipe_ids_lookup.get_vocabulary()[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a13318",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7131b0a",
   "metadata": {},
   "source": [
    "### Recipe id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c35e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_id_embedding = tf.keras.layers.Embedding(\n",
    "#                         input_dim=recipe_ids_lookup.vocabulary_size(),\n",
    "#                         output_dim=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c73e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_id_model = tf.keras.Sequential([recipe_ids_lookup, recipe_id_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2fb6a8",
   "metadata": {},
   "source": [
    "### User id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id_lookup = tf.keras.layers.StringLookup()\n",
    "# user_id_lookup.adapt(ratings.map(lambda x: x[\"AuthorId\"]))\n",
    "\n",
    "# user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocab_size(), 32)\n",
    "# user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db6c43",
   "metadata": {},
   "source": [
    "## Normalizing timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ed6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in ratings.take(3).as_numpy_iterator():\n",
    "#     print(f\"Timestamp: {x['Timestamp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_normalization = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "# timestamp_normalization.adapt(ratings.map(lambda x: x['Timestamp']).batch(1024))\n",
    "\n",
    "# for x in ratings.take(3).as_numpy_iterator():\n",
    "#     print(f\"Normalized timestamp: {timestamp_normalization(x['Timestamp'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc849a7",
   "metadata": {},
   "source": [
    "## Discretization timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ba00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"Timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_embedding_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "#     tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32)\n",
    "# ])\n",
    "\n",
    "# for timestamp in ratings.take(1).map(lambda x: x[\"Timestamp\"]).batch(1).as_numpy_iterator():\n",
    "#     print(f\"Timestamp embedding: {timestamp_embedding_model(timestamp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a0a6a",
   "metadata": {},
   "source": [
    "## Processing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_text = tf.keras.layers.TextVectorization()\n",
    "# title_text.adapt(recipes.map(lambda x: x['Name']).batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in recipes.take(1).map(lambda x: x['Name']).batch(1).as_numpy_iterator():\n",
    "#     print(title_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_text.get_vocabulary()[705] + \" \" + title_text.get_vocabulary()[2] + \" \" + title_text.get_vocabulary()[60] + \" \" + title_text.get_vocabulary()[433] + \" \" + title_text.get_vocabulary()[831]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f35af9",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(lambda x: x[\"AuthorId\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_recipe_names = np.unique(np.concatenate(list(recipes.batch(1_000).map(lambda x: x[\"Name\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_recipe_ids = np.unique(np.concatenate(list(recipes.batch(1_000).map(lambda x: x[\"RecipeId\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ec86a",
   "metadata": {},
   "source": [
    "## User model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, verbose=False):\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "        if(self._verbose):\n",
    "            print(\"USER MODEL INIT\")\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32),\n",
    "        ])\n",
    "        \n",
    "        self.normalized_timestamp = tf.keras.layers.Normalization(axis=None)\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"User model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"AuthorId\"]),\n",
    "            self.timestamp_embedding(inputs[\"Timestamp\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"Timestamp\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = UserModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Representation: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cbe96",
   "metadata": {},
   "source": [
    "## Recipe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, verbose=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "        self._verbose = verbose\n",
    "        if(verbose):\n",
    "            print(\"RECIPE MODEL INIT\")\n",
    "        self.recipe_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_recipe_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_recipe_ids)+1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.name_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        \n",
    "        self.name_text_embedding = tf.keras.Sequential([\n",
    "            self.name_vectorizer,\n",
    "            tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.name_vectorizer.adapt(recipes.map(lambda x: x['Name']))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Recipe model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "        return tf.concat([\n",
    "            self.recipe_id_embedding(inputs[\"RecipeId\"]),\n",
    "            self.name_text_embedding(inputs[\"Name\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c73ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_model = RecipeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in recipes.take(1).as_numpy_iterator():\n",
    "# #     print(x)\n",
    "#     print(recipe_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355d301",
   "metadata": {},
   "source": [
    "## Query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "        Args:\n",
    "            layer_sizes:\n",
    "        A list of integers where the i-th entry represents the number of units\n",
    "        the i-th layer contains.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Query model init\")\n",
    "            \n",
    "        self._verbose = verbose\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Query model call\")\n",
    "            print(\"Input: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35017010",
   "metadata": {},
   "source": [
    "## Candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73731716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        \"\"\"Model for encoding movies.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print(\"Candidate model init\")\n",
    "        self.embedding_model = RecipeModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "        self._verbose = verbose\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Candidate model call\")\n",
    "            print(\"Inputs: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66782c19",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print(\"Init combined model\")\n",
    "        self.query_model = QueryModel(layer_sizes)\n",
    "        self.candidate_model = CandidateModel(layer_sizes)\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=recipes.batch(128).map(self.candidate_model),\n",
    "            ),\n",
    "        )\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, features, training=False):\n",
    "        if(self._verbose):\n",
    "            print(\"Combined model compute loss\")\n",
    "            print(\"Features: \", features)\n",
    "        query_embeddings = self.query_model({\n",
    "            \"AuthorId\": features[\"AuthorId\"],\n",
    "            \"Timestamp\": features[\"Timestamp\"],\n",
    "        })\n",
    "        \n",
    "        recipe_embeddings = self.candidate_model({\n",
    "            \"RecipeId\": features[\"RecipeId\"],\n",
    "            \"Name\": features[\"Name\"]\n",
    "        })\n",
    "        \n",
    "        return self.task(\n",
    "            query_embeddings, recipe_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134118",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ratings_min_20.shape[0]\n",
    "train_size = int(0.8 * size)\n",
    "test_size = size - train_size\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings_merged.shuffle(size, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.take(train_size).take(test_size)\n",
    "\n",
    "cached_train = train.shuffle(1_000_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e50d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "model = CombinedModel([32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a660e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x1251059c160>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.query_model.dense_layers.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67fc9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 56s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 69633.9437 - regularization_loss: 0.0000e+00 - total_loss: 69633.9437\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 67056.2038 - regularization_loss: 0.0000e+00 - total_loss: 67056.2038\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 64506.9233 - regularization_loss: 0.0000e+00 - total_loss: 64506.9233\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 54s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 62583.9942 - regularization_loss: 0.0000e+00 - total_loss: 62583.9942\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 97s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 61116.9839 - regularization_loss: 0.0000e+00 - total_loss: 61116.9839 - val_factorized_top_k/top_1_categorical_accuracy: 0.0147 - val_factorized_top_k/top_5_categorical_accuracy: 0.0549 - val_factorized_top_k/top_10_categorical_accuracy: 0.0841 - val_factorized_top_k/top_50_categorical_accuracy: 0.1894 - val_factorized_top_k/top_100_categorical_accuracy: 0.2626 - val_loss: 2748.1321 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2748.1321\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 59957.1254 - regularization_loss: 0.0000e+00 - total_loss: 59957.1254\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 59009.9973 - regularization_loss: 0.0000e+00 - total_loss: 59009.9973\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 58225.0778 - regularization_loss: 0.0000e+00 - total_loss: 58225.0778\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 57567.1797 - regularization_loss: 0.0000e+00 - total_loss: 57567.1797\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 95s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 57010.0598 - regularization_loss: 0.0000e+00 - total_loss: 57010.0598 - val_factorized_top_k/top_1_categorical_accuracy: 0.0237 - val_factorized_top_k/top_5_categorical_accuracy: 0.0884 - val_factorized_top_k/top_10_categorical_accuracy: 0.1276 - val_factorized_top_k/top_50_categorical_accuracy: 0.2591 - val_factorized_top_k/top_100_categorical_accuracy: 0.3441 - val_loss: 2534.7056 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2534.7056\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 56532.9934 - regularization_loss: 0.0000e+00 - total_loss: 56532.9934\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 56119.2457 - regularization_loss: 0.0000e+00 - total_loss: 56119.2457\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 55755.9191 - regularization_loss: 0.0000e+00 - total_loss: 55755.9191\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 55433.8702 - regularization_loss: 0.0000e+00 - total_loss: 55433.8702\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 96s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 55146.4469 - regularization_loss: 0.0000e+00 - total_loss: 55146.4469 - val_factorized_top_k/top_1_categorical_accuracy: 0.0287 - val_factorized_top_k/top_5_categorical_accuracy: 0.1061 - val_factorized_top_k/top_10_categorical_accuracy: 0.1492 - val_factorized_top_k/top_50_categorical_accuracy: 0.2929 - val_factorized_top_k/top_100_categorical_accuracy: 0.3785 - val_loss: 2434.4404 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2434.4404\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 54888.0446 - regularization_loss: 0.0000e+00 - total_loss: 54888.0446\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 54653.7449 - regularization_loss: 0.0000e+00 - total_loss: 54653.7449\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 54439.5729 - regularization_loss: 0.0000e+00 - total_loss: 54439.5729\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 54242.1030 - regularization_loss: 0.0000e+00 - total_loss: 54242.1030\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 97s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 54058.7922 - regularization_loss: 0.0000e+00 - total_loss: 54058.7922 - val_factorized_top_k/top_1_categorical_accuracy: 0.0317 - val_factorized_top_k/top_5_categorical_accuracy: 0.1164 - val_factorized_top_k/top_10_categorical_accuracy: 0.1638 - val_factorized_top_k/top_50_categorical_accuracy: 0.3115 - val_factorized_top_k/top_100_categorical_accuracy: 0.3977 - val_loss: 2369.7854 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2369.7854\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53887.6006 - regularization_loss: 0.0000e+00 - total_loss: 53887.6006\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53727.1595 - regularization_loss: 0.0000e+00 - total_loss: 53727.1595\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53576.3796 - regularization_loss: 0.0000e+00 - total_loss: 53576.3796\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53434.5557 - regularization_loss: 0.0000e+00 - total_loss: 53434.5557\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 95s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53300.9249 - regularization_loss: 0.0000e+00 - total_loss: 53300.9249 - val_factorized_top_k/top_1_categorical_accuracy: 0.0341 - val_factorized_top_k/top_5_categorical_accuracy: 0.1251 - val_factorized_top_k/top_10_categorical_accuracy: 0.1743 - val_factorized_top_k/top_50_categorical_accuracy: 0.3248 - val_factorized_top_k/top_100_categorical_accuracy: 0.4115 - val_loss: 2324.7646 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2324.7646\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53174.9395 - regularization_loss: 0.0000e+00 - total_loss: 53174.9395\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 53055.8101 - regularization_loss: 0.0000e+00 - total_loss: 53055.8101\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52943.0762 - regularization_loss: 0.0000e+00 - total_loss: 52943.0762\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52836.0317 - regularization_loss: 0.0000e+00 - total_loss: 52836.0317\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 96s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52734.3888 - regularization_loss: 0.0000e+00 - total_loss: 52734.3888 - val_factorized_top_k/top_1_categorical_accuracy: 0.0350 - val_factorized_top_k/top_5_categorical_accuracy: 0.1320 - val_factorized_top_k/top_10_categorical_accuracy: 0.1826 - val_factorized_top_k/top_50_categorical_accuracy: 0.3348 - val_factorized_top_k/top_100_categorical_accuracy: 0.4215 - val_loss: 2292.0942 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2292.0942\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52637.5768 - regularization_loss: 0.0000e+00 - total_loss: 52637.5768\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52545.3408 - regularization_loss: 0.0000e+00 - total_loss: 52545.3408\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52457.2524 - regularization_loss: 0.0000e+00 - total_loss: 52457.2524\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52373.2034 - regularization_loss: 0.0000e+00 - total_loss: 52373.2034\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 95s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52292.7563 - regularization_loss: 0.0000e+00 - total_loss: 52292.7563 - val_factorized_top_k/top_1_categorical_accuracy: 0.0354 - val_factorized_top_k/top_5_categorical_accuracy: 0.1373 - val_factorized_top_k/top_10_categorical_accuracy: 0.1896 - val_factorized_top_k/top_50_categorical_accuracy: 0.3421 - val_factorized_top_k/top_100_categorical_accuracy: 0.4296 - val_loss: 2266.4172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2266.4172\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52215.9141 - regularization_loss: 0.0000e+00 - total_loss: 52215.9141\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52142.2704 - regularization_loss: 0.0000e+00 - total_loss: 52142.2704\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52071.8649 - regularization_loss: 0.0000e+00 - total_loss: 52071.8649\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 57s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 52004.3109 - regularization_loss: 0.0000e+00 - total_loss: 52004.3109\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51939.6614 - regularization_loss: 0.0000e+00 - total_loss: 51939.6614 - val_factorized_top_k/top_1_categorical_accuracy: 0.0371 - val_factorized_top_k/top_5_categorical_accuracy: 0.1423 - val_factorized_top_k/top_10_categorical_accuracy: 0.1943 - val_factorized_top_k/top_50_categorical_accuracy: 0.3483 - val_factorized_top_k/top_100_categorical_accuracy: 0.4362 - val_loss: 2246.1841 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2246.1841\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51877.5674 - regularization_loss: 0.0000e+00 - total_loss: 51877.5674\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51818.0756 - regularization_loss: 0.0000e+00 - total_loss: 51818.0756\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51760.8922 - regularization_loss: 0.0000e+00 - total_loss: 51760.8922\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 53s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51705.9802 - regularization_loss: 0.0000e+00 - total_loss: 51705.9802\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51653.0997 - regularization_loss: 0.0000e+00 - total_loss: 51653.0997 - val_factorized_top_k/top_1_categorical_accuracy: 0.0385 - val_factorized_top_k/top_5_categorical_accuracy: 0.1454 - val_factorized_top_k/top_10_categorical_accuracy: 0.1985 - val_factorized_top_k/top_50_categorical_accuracy: 0.3535 - val_factorized_top_k/top_100_categorical_accuracy: 0.4407 - val_loss: 2230.0979 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2230.0979\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51602.2007 - regularization_loss: 0.0000e+00 - total_loss: 51602.2007\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51553.1473 - regularization_loss: 0.0000e+00 - total_loss: 51553.1473\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51505.9407 - regularization_loss: 0.0000e+00 - total_loss: 51505.9407\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51460.2673 - regularization_loss: 0.0000e+00 - total_loss: 51460.2673\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51416.2627 - regularization_loss: 0.0000e+00 - total_loss: 51416.2627 - val_factorized_top_k/top_1_categorical_accuracy: 0.0382 - val_factorized_top_k/top_5_categorical_accuracy: 0.1476 - val_factorized_top_k/top_10_categorical_accuracy: 0.2021 - val_factorized_top_k/top_50_categorical_accuracy: 0.3578 - val_factorized_top_k/top_100_categorical_accuracy: 0.4447 - val_loss: 2217.0732 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2217.0732\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51373.6195 - regularization_loss: 0.0000e+00 - total_loss: 51373.6195\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51332.4628 - regularization_loss: 0.0000e+00 - total_loss: 51332.4628\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51292.5193 - regularization_loss: 0.0000e+00 - total_loss: 51292.5193\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51253.9018 - regularization_loss: 0.0000e+00 - total_loss: 51253.9018\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51216.3688 - regularization_loss: 0.0000e+00 - total_loss: 51216.3688 - val_factorized_top_k/top_1_categorical_accuracy: 0.0390 - val_factorized_top_k/top_5_categorical_accuracy: 0.1504 - val_factorized_top_k/top_10_categorical_accuracy: 0.2060 - val_factorized_top_k/top_50_categorical_accuracy: 0.3612 - val_factorized_top_k/top_100_categorical_accuracy: 0.4481 - val_loss: 2206.3125 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2206.3125\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51180.0174 - regularization_loss: 0.0000e+00 - total_loss: 51180.0174\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51144.6538 - regularization_loss: 0.0000e+00 - total_loss: 51144.6538\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51110.3413 - regularization_loss: 0.0000e+00 - total_loss: 51110.3413\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51076.9235 - regularization_loss: 0.0000e+00 - total_loss: 51076.9235\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51044.4476 - regularization_loss: 0.0000e+00 - total_loss: 51044.4476 - val_factorized_top_k/top_1_categorical_accuracy: 0.0390 - val_factorized_top_k/top_5_categorical_accuracy: 0.1522 - val_factorized_top_k/top_10_categorical_accuracy: 0.2087 - val_factorized_top_k/top_50_categorical_accuracy: 0.3647 - val_factorized_top_k/top_100_categorical_accuracy: 0.4509 - val_loss: 2197.2456 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2197.2456\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 51012.7827 - regularization_loss: 0.0000e+00 - total_loss: 51012.7827\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50981.9763 - regularization_loss: 0.0000e+00 - total_loss: 50981.9763\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50951.9133 - regularization_loss: 0.0000e+00 - total_loss: 50951.9133\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50922.6318 - regularization_loss: 0.0000e+00 - total_loss: 50922.6318\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50894.0229 - regularization_loss: 0.0000e+00 - total_loss: 50894.0229 - val_factorized_top_k/top_1_categorical_accuracy: 0.0393 - val_factorized_top_k/top_5_categorical_accuracy: 0.1535 - val_factorized_top_k/top_10_categorical_accuracy: 0.2109 - val_factorized_top_k/top_50_categorical_accuracy: 0.3675 - val_factorized_top_k/top_100_categorical_accuracy: 0.4527 - val_loss: 2189.2954 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2189.2954\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50866.1353 - regularization_loss: 0.0000e+00 - total_loss: 50866.1353\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50838.8592 - regularization_loss: 0.0000e+00 - total_loss: 50838.8592\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50812.2493 - regularization_loss: 0.0000e+00 - total_loss: 50812.2493\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50786.1945 - regularization_loss: 0.0000e+00 - total_loss: 50786.1945\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50760.7563 - regularization_loss: 0.0000e+00 - total_loss: 50760.7563 - val_factorized_top_k/top_1_categorical_accuracy: 0.0406 - val_factorized_top_k/top_5_categorical_accuracy: 0.1553 - val_factorized_top_k/top_10_categorical_accuracy: 0.2134 - val_factorized_top_k/top_50_categorical_accuracy: 0.3700 - val_factorized_top_k/top_100_categorical_accuracy: 0.4548 - val_loss: 2182.2551 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2182.2551\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50735.8217 - regularization_loss: 0.0000e+00 - total_loss: 50735.8217\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50711.4637 - regularization_loss: 0.0000e+00 - total_loss: 50711.4637\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50687.5593 - regularization_loss: 0.0000e+00 - total_loss: 50687.5593\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50664.2094 - regularization_loss: 0.0000e+00 - total_loss: 50664.2094\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50641.2689 - regularization_loss: 0.0000e+00 - total_loss: 50641.2689 - val_factorized_top_k/top_1_categorical_accuracy: 0.0405 - val_factorized_top_k/top_5_categorical_accuracy: 0.1571 - val_factorized_top_k/top_10_categorical_accuracy: 0.2153 - val_factorized_top_k/top_50_categorical_accuracy: 0.3721 - val_factorized_top_k/top_100_categorical_accuracy: 0.4564 - val_loss: 2175.7844 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2175.7844\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50618.8450 - regularization_loss: 0.0000e+00 - total_loss: 50618.8450\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50596.7971 - regularization_loss: 0.0000e+00 - total_loss: 50596.7971\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50575.2402 - regularization_loss: 0.0000e+00 - total_loss: 50575.2402\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50554.0221 - regularization_loss: 0.0000e+00 - total_loss: 50554.0221\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50533.2695 - regularization_loss: 0.0000e+00 - total_loss: 50533.2695 - val_factorized_top_k/top_1_categorical_accuracy: 0.0403 - val_factorized_top_k/top_5_categorical_accuracy: 0.1582 - val_factorized_top_k/top_10_categorical_accuracy: 0.2173 - val_factorized_top_k/top_50_categorical_accuracy: 0.3741 - val_factorized_top_k/top_100_categorical_accuracy: 0.4579 - val_loss: 2169.8950 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2169.8950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50512.8297 - regularization_loss: 0.0000e+00 - total_loss: 50512.8297\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50492.8315 - regularization_loss: 0.0000e+00 - total_loss: 50492.8315\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50473.1146 - regularization_loss: 0.0000e+00 - total_loss: 50473.1146\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50453.8217 - regularization_loss: 0.0000e+00 - total_loss: 50453.8217\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50434.7842 - regularization_loss: 0.0000e+00 - total_loss: 50434.7842 - val_factorized_top_k/top_1_categorical_accuracy: 0.0407 - val_factorized_top_k/top_5_categorical_accuracy: 0.1603 - val_factorized_top_k/top_10_categorical_accuracy: 0.2191 - val_factorized_top_k/top_50_categorical_accuracy: 0.3754 - val_factorized_top_k/top_100_categorical_accuracy: 0.4591 - val_loss: 2164.3689 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2164.3689\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50416.1515 - regularization_loss: 0.0000e+00 - total_loss: 50416.1515\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50397.7537 - regularization_loss: 0.0000e+00 - total_loss: 50397.7537\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50379.7411 - regularization_loss: 0.0000e+00 - total_loss: 50379.7411\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50361.9411 - regularization_loss: 0.0000e+00 - total_loss: 50361.9411\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50344.5122 - regularization_loss: 0.0000e+00 - total_loss: 50344.5122 - val_factorized_top_k/top_1_categorical_accuracy: 0.0414 - val_factorized_top_k/top_5_categorical_accuracy: 0.1611 - val_factorized_top_k/top_10_categorical_accuracy: 0.2204 - val_factorized_top_k/top_50_categorical_accuracy: 0.3771 - val_factorized_top_k/top_100_categorical_accuracy: 0.4606 - val_loss: 2159.2522 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2159.2522\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50327.2798 - regularization_loss: 0.0000e+00 - total_loss: 50327.2798\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50310.3998 - regularization_loss: 0.0000e+00 - total_loss: 50310.3998\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50293.7045 - regularization_loss: 0.0000e+00 - total_loss: 50293.7045\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50277.3409 - regularization_loss: 0.0000e+00 - total_loss: 50277.3409\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50261.1525 - regularization_loss: 0.0000e+00 - total_loss: 50261.1525 - val_factorized_top_k/top_1_categorical_accuracy: 0.0406 - val_factorized_top_k/top_5_categorical_accuracy: 0.1623 - val_factorized_top_k/top_10_categorical_accuracy: 0.2224 - val_factorized_top_k/top_50_categorical_accuracy: 0.3786 - val_factorized_top_k/top_100_categorical_accuracy: 0.4612 - val_loss: 2154.4209 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2154.4209\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50245.2774 - regularization_loss: 0.0000e+00 - total_loss: 50245.2774\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50229.5711 - regularization_loss: 0.0000e+00 - total_loss: 50229.5711\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50214.1553 - regularization_loss: 0.0000e+00 - total_loss: 50214.1553\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50198.9084 - regularization_loss: 0.0000e+00 - total_loss: 50198.9084\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50183.9318 - regularization_loss: 0.0000e+00 - total_loss: 50183.9318 - val_factorized_top_k/top_1_categorical_accuracy: 0.0408 - val_factorized_top_k/top_5_categorical_accuracy: 0.1636 - val_factorized_top_k/top_10_categorical_accuracy: 0.2235 - val_factorized_top_k/top_50_categorical_accuracy: 0.3799 - val_factorized_top_k/top_100_categorical_accuracy: 0.4628 - val_loss: 2149.8904 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2149.8904\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50169.1187 - regularization_loss: 0.0000e+00 - total_loss: 50169.1187\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50154.5510 - regularization_loss: 0.0000e+00 - total_loss: 50154.5510\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50140.1473 - regularization_loss: 0.0000e+00 - total_loss: 50140.1473\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50125.9753 - regularization_loss: 0.0000e+00 - total_loss: 50125.9753\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50111.9612 - regularization_loss: 0.0000e+00 - total_loss: 50111.9612 - val_factorized_top_k/top_1_categorical_accuracy: 0.0410 - val_factorized_top_k/top_5_categorical_accuracy: 0.1649 - val_factorized_top_k/top_10_categorical_accuracy: 0.2253 - val_factorized_top_k/top_50_categorical_accuracy: 0.3811 - val_factorized_top_k/top_100_categorical_accuracy: 0.4637 - val_loss: 2145.6128 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2145.6128\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50098.1647 - regularization_loss: 0.0000e+00 - total_loss: 50098.1647\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50084.5182 - regularization_loss: 0.0000e+00 - total_loss: 50084.5182\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50071.0831 - regularization_loss: 0.0000e+00 - total_loss: 50071.0831\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50057.7881 - regularization_loss: 0.0000e+00 - total_loss: 50057.7881\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50044.6977 - regularization_loss: 0.0000e+00 - total_loss: 50044.6977 - val_factorized_top_k/top_1_categorical_accuracy: 0.0408 - val_factorized_top_k/top_5_categorical_accuracy: 0.1660 - val_factorized_top_k/top_10_categorical_accuracy: 0.2265 - val_factorized_top_k/top_50_categorical_accuracy: 0.3824 - val_factorized_top_k/top_100_categorical_accuracy: 0.4643 - val_loss: 2141.5725 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2141.5725\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50031.7373 - regularization_loss: 0.0000e+00 - total_loss: 50031.7373\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50018.9748 - regularization_loss: 0.0000e+00 - total_loss: 50018.9748\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 50006.3326 - regularization_loss: 0.0000e+00 - total_loss: 50006.3326\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49993.8818 - regularization_loss: 0.0000e+00 - total_loss: 49993.8818\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49981.5515 - regularization_loss: 0.0000e+00 - total_loss: 49981.5515 - val_factorized_top_k/top_1_categorical_accuracy: 0.0410 - val_factorized_top_k/top_5_categorical_accuracy: 0.1663 - val_factorized_top_k/top_10_categorical_accuracy: 0.2278 - val_factorized_top_k/top_50_categorical_accuracy: 0.3837 - val_factorized_top_k/top_100_categorical_accuracy: 0.4654 - val_loss: 2137.7578 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2137.7578\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49969.3984 - regularization_loss: 0.0000e+00 - total_loss: 49969.3984\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49957.3629 - regularization_loss: 0.0000e+00 - total_loss: 49957.3629\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49945.4953 - regularization_loss: 0.0000e+00 - total_loss: 49945.4953\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 52s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49933.7403 - regularization_loss: 0.0000e+00 - total_loss: 49933.7403\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49922.1470 - regularization_loss: 0.0000e+00 - total_loss: 49922.1470 - val_factorized_top_k/top_1_categorical_accuracy: 0.0416 - val_factorized_top_k/top_5_categorical_accuracy: 0.1673 - val_factorized_top_k/top_10_categorical_accuracy: 0.2287 - val_factorized_top_k/top_50_categorical_accuracy: 0.3848 - val_factorized_top_k/top_100_categorical_accuracy: 0.4662 - val_loss: 2134.1353 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2134.1353\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49910.6650 - regularization_loss: 0.0000e+00 - total_loss: 49910.6650\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49899.3358 - regularization_loss: 0.0000e+00 - total_loss: 49899.3358\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49888.1141 - regularization_loss: 0.0000e+00 - total_loss: 49888.1141\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49877.0485 - regularization_loss: 0.0000e+00 - total_loss: 49877.0485\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49866.1404 - regularization_loss: 0.0000e+00 - total_loss: 49866.1404 - val_factorized_top_k/top_1_categorical_accuracy: 0.0419 - val_factorized_top_k/top_5_categorical_accuracy: 0.1678 - val_factorized_top_k/top_10_categorical_accuracy: 0.2304 - val_factorized_top_k/top_50_categorical_accuracy: 0.3857 - val_factorized_top_k/top_100_categorical_accuracy: 0.4664 - val_loss: 2130.7439 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2130.7439\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49855.3384 - regularization_loss: 0.0000e+00 - total_loss: 49855.3384\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49844.6791 - regularization_loss: 0.0000e+00 - total_loss: 49844.6791\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49833.8735 - regularization_loss: 0.0000e+00 - total_loss: 49833.8735\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49823.3611 - regularization_loss: 0.0000e+00 - total_loss: 49823.3611\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49812.9774 - regularization_loss: 0.0000e+00 - total_loss: 49812.9774 - val_factorized_top_k/top_1_categorical_accuracy: 0.0418 - val_factorized_top_k/top_5_categorical_accuracy: 0.1690 - val_factorized_top_k/top_10_categorical_accuracy: 0.2315 - val_factorized_top_k/top_50_categorical_accuracy: 0.3864 - val_factorized_top_k/top_100_categorical_accuracy: 0.4677 - val_loss: 2127.4688 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2127.4688\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49802.6962 - regularization_loss: 0.0000e+00 - total_loss: 49802.6962\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49792.5258 - regularization_loss: 0.0000e+00 - total_loss: 49792.5258\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49782.4570 - regularization_loss: 0.0000e+00 - total_loss: 49782.4570\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49772.4907 - regularization_loss: 0.0000e+00 - total_loss: 49772.4907\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49762.6257 - regularization_loss: 0.0000e+00 - total_loss: 49762.6257 - val_factorized_top_k/top_1_categorical_accuracy: 0.0414 - val_factorized_top_k/top_5_categorical_accuracy: 0.1698 - val_factorized_top_k/top_10_categorical_accuracy: 0.2326 - val_factorized_top_k/top_50_categorical_accuracy: 0.3873 - val_factorized_top_k/top_100_categorical_accuracy: 0.4682 - val_loss: 2124.4170 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2124.4170\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49752.8617 - regularization_loss: 0.0000e+00 - total_loss: 49752.8617\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49743.1924 - regularization_loss: 0.0000e+00 - total_loss: 49743.1924\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49733.6227 - regularization_loss: 0.0000e+00 - total_loss: 49733.6227\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49724.1437 - regularization_loss: 0.0000e+00 - total_loss: 49724.1437\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49714.7590 - regularization_loss: 0.0000e+00 - total_loss: 49714.7590 - val_factorized_top_k/top_1_categorical_accuracy: 0.0410 - val_factorized_top_k/top_5_categorical_accuracy: 0.1702 - val_factorized_top_k/top_10_categorical_accuracy: 0.2337 - val_factorized_top_k/top_50_categorical_accuracy: 0.3884 - val_factorized_top_k/top_100_categorical_accuracy: 0.4686 - val_loss: 2121.4688 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2121.4688\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49705.4628 - regularization_loss: 0.0000e+00 - total_loss: 49705.4628\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49696.2589 - regularization_loss: 0.0000e+00 - total_loss: 49696.2589\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49687.1447 - regularization_loss: 0.0000e+00 - total_loss: 49687.1447\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49678.1130 - regularization_loss: 0.0000e+00 - total_loss: 49678.1130\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49669.1713 - regularization_loss: 0.0000e+00 - total_loss: 49669.1713 - val_factorized_top_k/top_1_categorical_accuracy: 0.0420 - val_factorized_top_k/top_5_categorical_accuracy: 0.1712 - val_factorized_top_k/top_10_categorical_accuracy: 0.2343 - val_factorized_top_k/top_50_categorical_accuracy: 0.3893 - val_factorized_top_k/top_100_categorical_accuracy: 0.4692 - val_loss: 2118.7405 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2118.7405\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49660.3017 - regularization_loss: 0.0000e+00 - total_loss: 49660.3017\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49651.5196 - regularization_loss: 0.0000e+00 - total_loss: 49651.5196\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49642.8129 - regularization_loss: 0.0000e+00 - total_loss: 49642.8129\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49634.1932 - regularization_loss: 0.0000e+00 - total_loss: 49634.1932\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49625.6443 - regularization_loss: 0.0000e+00 - total_loss: 49625.6443 - val_factorized_top_k/top_1_categorical_accuracy: 0.0409 - val_factorized_top_k/top_5_categorical_accuracy: 0.1716 - val_factorized_top_k/top_10_categorical_accuracy: 0.2357 - val_factorized_top_k/top_50_categorical_accuracy: 0.3899 - val_factorized_top_k/top_100_categorical_accuracy: 0.4699 - val_loss: 2116.0676 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2116.0676\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49617.1780 - regularization_loss: 0.0000e+00 - total_loss: 49617.1780\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49608.7773 - regularization_loss: 0.0000e+00 - total_loss: 49608.7773\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49600.4627 - regularization_loss: 0.0000e+00 - total_loss: 49600.4627\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49592.2082 - regularization_loss: 0.0000e+00 - total_loss: 49592.2082\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49584.0338 - regularization_loss: 0.0000e+00 - total_loss: 49584.0338 - val_factorized_top_k/top_1_categorical_accuracy: 0.0419 - val_factorized_top_k/top_5_categorical_accuracy: 0.1723 - val_factorized_top_k/top_10_categorical_accuracy: 0.2364 - val_factorized_top_k/top_50_categorical_accuracy: 0.3905 - val_factorized_top_k/top_100_categorical_accuracy: 0.4707 - val_loss: 2113.6121 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2113.6121\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49575.9222 - regularization_loss: 0.0000e+00 - total_loss: 49575.9222\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49567.8851 - regularization_loss: 0.0000e+00 - total_loss: 49567.8851\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49559.9106 - regularization_loss: 0.0000e+00 - total_loss: 49559.9106\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49552.0105 - regularization_loss: 0.0000e+00 - total_loss: 49552.0105\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49544.1719 - regularization_loss: 0.0000e+00 - total_loss: 49544.1719 - val_factorized_top_k/top_1_categorical_accuracy: 0.0417 - val_factorized_top_k/top_5_categorical_accuracy: 0.1731 - val_factorized_top_k/top_10_categorical_accuracy: 0.2372 - val_factorized_top_k/top_50_categorical_accuracy: 0.3913 - val_factorized_top_k/top_100_categorical_accuracy: 0.4715 - val_loss: 2111.1836 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2111.1836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49536.4009 - regularization_loss: 0.0000e+00 - total_loss: 49536.4009\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49528.6941 - regularization_loss: 0.0000e+00 - total_loss: 49528.6941\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49521.0525 - regularization_loss: 0.0000e+00 - total_loss: 49521.0525\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49513.4738 - regularization_loss: 0.0000e+00 - total_loss: 49513.4738\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49505.9564 - regularization_loss: 0.0000e+00 - total_loss: 49505.9564 - val_factorized_top_k/top_1_categorical_accuracy: 0.0414 - val_factorized_top_k/top_5_categorical_accuracy: 0.1732 - val_factorized_top_k/top_10_categorical_accuracy: 0.2382 - val_factorized_top_k/top_50_categorical_accuracy: 0.3919 - val_factorized_top_k/top_100_categorical_accuracy: 0.4722 - val_loss: 2108.9678 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2108.9678\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49498.5012 - regularization_loss: 0.0000e+00 - total_loss: 49498.5012\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49491.1119 - regularization_loss: 0.0000e+00 - total_loss: 49491.1119\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49483.8030 - regularization_loss: 0.0000e+00 - total_loss: 49483.8030\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49476.6180 - regularization_loss: 0.0000e+00 - total_loss: 49476.6180\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49469.3122 - regularization_loss: 0.0000e+00 - total_loss: 49469.3122 - val_factorized_top_k/top_1_categorical_accuracy: 0.0413 - val_factorized_top_k/top_5_categorical_accuracy: 0.1740 - val_factorized_top_k/top_10_categorical_accuracy: 0.2389 - val_factorized_top_k/top_50_categorical_accuracy: 0.3925 - val_factorized_top_k/top_100_categorical_accuracy: 0.4730 - val_loss: 2106.7488 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2106.7488\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49462.1351 - regularization_loss: 0.0000e+00 - total_loss: 49462.1351\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49454.9932 - regularization_loss: 0.0000e+00 - total_loss: 49454.9932\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49447.9216 - regularization_loss: 0.0000e+00 - total_loss: 49447.9216\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49440.9130 - regularization_loss: 0.0000e+00 - total_loss: 49440.9130\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49433.9579 - regularization_loss: 0.0000e+00 - total_loss: 49433.9579 - val_factorized_top_k/top_1_categorical_accuracy: 0.0420 - val_factorized_top_k/top_5_categorical_accuracy: 0.1744 - val_factorized_top_k/top_10_categorical_accuracy: 0.2399 - val_factorized_top_k/top_50_categorical_accuracy: 0.3934 - val_factorized_top_k/top_100_categorical_accuracy: 0.4733 - val_loss: 2104.7495 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2104.7495\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49427.0648 - regularization_loss: 0.0000e+00 - total_loss: 49427.0648\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49420.2122 - regularization_loss: 0.0000e+00 - total_loss: 49420.2122\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49413.4241 - regularization_loss: 0.0000e+00 - total_loss: 49413.4241\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49406.6736 - regularization_loss: 0.0000e+00 - total_loss: 49406.6736\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49399.9865 - regularization_loss: 0.0000e+00 - total_loss: 49399.9865 - val_factorized_top_k/top_1_categorical_accuracy: 0.0425 - val_factorized_top_k/top_5_categorical_accuracy: 0.1746 - val_factorized_top_k/top_10_categorical_accuracy: 0.2407 - val_factorized_top_k/top_50_categorical_accuracy: 0.3938 - val_factorized_top_k/top_100_categorical_accuracy: 0.4736 - val_loss: 2102.7368 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2102.7368\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49393.3340 - regularization_loss: 0.0000e+00 - total_loss: 49393.3340\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49386.7463 - regularization_loss: 0.0000e+00 - total_loss: 49386.7463\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49380.1882 - regularization_loss: 0.0000e+00 - total_loss: 49380.1882\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49373.6942 - regularization_loss: 0.0000e+00 - total_loss: 49373.6942\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49367.2301 - regularization_loss: 0.0000e+00 - total_loss: 49367.2301 - val_factorized_top_k/top_1_categorical_accuracy: 0.0413 - val_factorized_top_k/top_5_categorical_accuracy: 0.1750 - val_factorized_top_k/top_10_categorical_accuracy: 0.2412 - val_factorized_top_k/top_50_categorical_accuracy: 0.3944 - val_factorized_top_k/top_100_categorical_accuracy: 0.4739 - val_loss: 2100.9250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2100.9250\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49360.8303 - regularization_loss: 0.0000e+00 - total_loss: 49360.8303\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49354.4569 - regularization_loss: 0.0000e+00 - total_loss: 49354.4569\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49348.1490 - regularization_loss: 0.0000e+00 - total_loss: 49348.1490\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49341.8649 - regularization_loss: 0.0000e+00 - total_loss: 49341.8649\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49335.6451 - regularization_loss: 0.0000e+00 - total_loss: 49335.6451 - val_factorized_top_k/top_1_categorical_accuracy: 0.0413 - val_factorized_top_k/top_5_categorical_accuracy: 0.1756 - val_factorized_top_k/top_10_categorical_accuracy: 0.2421 - val_factorized_top_k/top_50_categorical_accuracy: 0.3950 - val_factorized_top_k/top_100_categorical_accuracy: 0.4745 - val_loss: 2099.0750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2099.0750\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49329.4445 - regularization_loss: 0.0000e+00 - total_loss: 49329.4445\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49323.3117 - regularization_loss: 0.0000e+00 - total_loss: 49323.3117\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49317.1961 - regularization_loss: 0.0000e+00 - total_loss: 49317.1961\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49311.1445 - regularization_loss: 0.0000e+00 - total_loss: 49311.1445\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49305.1154 - regularization_loss: 0.0000e+00 - total_loss: 49305.1154 - val_factorized_top_k/top_1_categorical_accuracy: 0.0418 - val_factorized_top_k/top_5_categorical_accuracy: 0.1763 - val_factorized_top_k/top_10_categorical_accuracy: 0.2430 - val_factorized_top_k/top_50_categorical_accuracy: 0.3958 - val_factorized_top_k/top_100_categorical_accuracy: 0.4750 - val_loss: 2097.4333 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2097.4333\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49299.1436 - regularization_loss: 0.0000e+00 - total_loss: 49299.1436\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49293.1976 - regularization_loss: 0.0000e+00 - total_loss: 49293.1976\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49287.3019 - regularization_loss: 0.0000e+00 - total_loss: 49287.3019\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49281.4342 - regularization_loss: 0.0000e+00 - total_loss: 49281.4342\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49275.6172 - regularization_loss: 0.0000e+00 - total_loss: 49275.6172 - val_factorized_top_k/top_1_categorical_accuracy: 0.0415 - val_factorized_top_k/top_5_categorical_accuracy: 0.1765 - val_factorized_top_k/top_10_categorical_accuracy: 0.2437 - val_factorized_top_k/top_50_categorical_accuracy: 0.3965 - val_factorized_top_k/top_100_categorical_accuracy: 0.4755 - val_loss: 2095.7434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2095.7434\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49269.8244 - regularization_loss: 0.0000e+00 - total_loss: 49269.8244\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49264.0844 - regularization_loss: 0.0000e+00 - total_loss: 49264.0844\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49258.3663 - regularization_loss: 0.0000e+00 - total_loss: 49258.3663\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49252.7063 - regularization_loss: 0.0000e+00 - total_loss: 49252.7063\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49247.0575 - regularization_loss: 0.0000e+00 - total_loss: 49247.0575 - val_factorized_top_k/top_1_categorical_accuracy: 0.0417 - val_factorized_top_k/top_5_categorical_accuracy: 0.1768 - val_factorized_top_k/top_10_categorical_accuracy: 0.2440 - val_factorized_top_k/top_50_categorical_accuracy: 0.3972 - val_factorized_top_k/top_100_categorical_accuracy: 0.4760 - val_loss: 2094.2566 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2094.2566\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49241.4737 - regularization_loss: 0.0000e+00 - total_loss: 49241.4737\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49235.8959 - regularization_loss: 0.0000e+00 - total_loss: 49235.8959\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49230.3767 - regularization_loss: 0.0000e+00 - total_loss: 49230.3767\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49224.8723 - regularization_loss: 0.0000e+00 - total_loss: 49224.8723\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49219.4155 - regularization_loss: 0.0000e+00 - total_loss: 49219.4155 - val_factorized_top_k/top_1_categorical_accuracy: 0.0414 - val_factorized_top_k/top_5_categorical_accuracy: 0.1772 - val_factorized_top_k/top_10_categorical_accuracy: 0.2448 - val_factorized_top_k/top_50_categorical_accuracy: 0.3978 - val_factorized_top_k/top_100_categorical_accuracy: 0.4767 - val_loss: 2092.7024 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2092.7024\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49213.9895 - regularization_loss: 0.0000e+00 - total_loss: 49213.9895\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49208.5936 - regularization_loss: 0.0000e+00 - total_loss: 49208.5936\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49203.2418 - regularization_loss: 0.0000e+00 - total_loss: 49203.2418\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49197.9072 - regularization_loss: 0.0000e+00 - total_loss: 49197.9072\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49192.6184 - regularization_loss: 0.0000e+00 - total_loss: 49192.6184 - val_factorized_top_k/top_1_categorical_accuracy: 0.0408 - val_factorized_top_k/top_5_categorical_accuracy: 0.1778 - val_factorized_top_k/top_10_categorical_accuracy: 0.2451 - val_factorized_top_k/top_50_categorical_accuracy: 0.3983 - val_factorized_top_k/top_100_categorical_accuracy: 0.4768 - val_loss: 2091.3276 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2091.3276\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49187.3431 - regularization_loss: 0.0000e+00 - total_loss: 49187.3431\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49182.1171 - regularization_loss: 0.0000e+00 - total_loss: 49182.1171\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49176.9122 - regularization_loss: 0.0000e+00 - total_loss: 49176.9122\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49171.7437 - regularization_loss: 0.0000e+00 - total_loss: 49171.7437\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49166.6091 - regularization_loss: 0.0000e+00 - total_loss: 49166.6091 - val_factorized_top_k/top_1_categorical_accuracy: 0.0404 - val_factorized_top_k/top_5_categorical_accuracy: 0.1780 - val_factorized_top_k/top_10_categorical_accuracy: 0.2458 - val_factorized_top_k/top_50_categorical_accuracy: 0.3986 - val_factorized_top_k/top_100_categorical_accuracy: 0.4774 - val_loss: 2089.8987 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2089.8987\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49161.5003 - regularization_loss: 0.0000e+00 - total_loss: 49161.5003\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49156.4357 - regularization_loss: 0.0000e+00 - total_loss: 49156.4357\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49151.3874 - regularization_loss: 0.0000e+00 - total_loss: 49151.3874\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49146.3826 - regularization_loss: 0.0000e+00 - total_loss: 49146.3826\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49141.3922 - regularization_loss: 0.0000e+00 - total_loss: 49141.3922 - val_factorized_top_k/top_1_categorical_accuracy: 0.0407 - val_factorized_top_k/top_5_categorical_accuracy: 0.1781 - val_factorized_top_k/top_10_categorical_accuracy: 0.2466 - val_factorized_top_k/top_50_categorical_accuracy: 0.3994 - val_factorized_top_k/top_100_categorical_accuracy: 0.4780 - val_loss: 2088.6604 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2088.6604\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49136.4846 - regularization_loss: 0.0000e+00 - total_loss: 49136.4846\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49131.6196 - regularization_loss: 0.0000e+00 - total_loss: 49131.6196\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49126.5967 - regularization_loss: 0.0000e+00 - total_loss: 49126.5967\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49121.7022 - regularization_loss: 0.0000e+00 - total_loss: 49121.7022\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49116.8409 - regularization_loss: 0.0000e+00 - total_loss: 49116.8409 - val_factorized_top_k/top_1_categorical_accuracy: 0.0405 - val_factorized_top_k/top_5_categorical_accuracy: 0.1785 - val_factorized_top_k/top_10_categorical_accuracy: 0.2467 - val_factorized_top_k/top_50_categorical_accuracy: 0.3997 - val_factorized_top_k/top_100_categorical_accuracy: 0.4781 - val_loss: 2087.3457 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2087.3457\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49112.0297 - regularization_loss: 0.0000e+00 - total_loss: 49112.0297\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49107.2266 - regularization_loss: 0.0000e+00 - total_loss: 49107.2266\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49102.4675 - regularization_loss: 0.0000e+00 - total_loss: 49102.4675\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49097.7179 - regularization_loss: 0.0000e+00 - total_loss: 49097.7179\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49093.0109 - regularization_loss: 0.0000e+00 - total_loss: 49093.0109 - val_factorized_top_k/top_1_categorical_accuracy: 0.0403 - val_factorized_top_k/top_5_categorical_accuracy: 0.1785 - val_factorized_top_k/top_10_categorical_accuracy: 0.2480 - val_factorized_top_k/top_50_categorical_accuracy: 0.4001 - val_factorized_top_k/top_100_categorical_accuracy: 0.4786 - val_loss: 2086.1948 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2086.1948\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49088.3179 - regularization_loss: 0.0000e+00 - total_loss: 49088.3179\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49083.6588 - regularization_loss: 0.0000e+00 - total_loss: 49083.6588\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49079.0216 - regularization_loss: 0.0000e+00 - total_loss: 49079.0216\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49074.4105 - regularization_loss: 0.0000e+00 - total_loss: 49074.4105\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49069.8247 - regularization_loss: 0.0000e+00 - total_loss: 49069.8247 - val_factorized_top_k/top_1_categorical_accuracy: 0.0402 - val_factorized_top_k/top_5_categorical_accuracy: 0.1791 - val_factorized_top_k/top_10_categorical_accuracy: 0.2484 - val_factorized_top_k/top_50_categorical_accuracy: 0.4006 - val_factorized_top_k/top_100_categorical_accuracy: 0.4790 - val_loss: 2084.9841 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2084.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49065.2635 - regularization_loss: 0.0000e+00 - total_loss: 49065.2635\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49060.7235 - regularization_loss: 0.0000e+00 - total_loss: 49060.7235\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49056.2125 - regularization_loss: 0.0000e+00 - total_loss: 49056.2125\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49051.7174 - regularization_loss: 0.0000e+00 - total_loss: 49051.7174\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49047.2593 - regularization_loss: 0.0000e+00 - total_loss: 49047.2593 - val_factorized_top_k/top_1_categorical_accuracy: 0.0403 - val_factorized_top_k/top_5_categorical_accuracy: 0.1794 - val_factorized_top_k/top_10_categorical_accuracy: 0.2487 - val_factorized_top_k/top_50_categorical_accuracy: 0.4009 - val_factorized_top_k/top_100_categorical_accuracy: 0.4792 - val_loss: 2083.9253 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2083.9253\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49042.8073 - regularization_loss: 0.0000e+00 - total_loss: 49042.8073\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49038.4009 - regularization_loss: 0.0000e+00 - total_loss: 49038.4009\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49033.9918 - regularization_loss: 0.0000e+00 - total_loss: 49033.9918\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49029.6333 - regularization_loss: 0.0000e+00 - total_loss: 49029.6333\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49025.2658 - regularization_loss: 0.0000e+00 - total_loss: 49025.2658 - val_factorized_top_k/top_1_categorical_accuracy: 0.0393 - val_factorized_top_k/top_5_categorical_accuracy: 0.1797 - val_factorized_top_k/top_10_categorical_accuracy: 0.2489 - val_factorized_top_k/top_50_categorical_accuracy: 0.4013 - val_factorized_top_k/top_100_categorical_accuracy: 0.4798 - val_loss: 2082.8088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2082.8088\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49020.9555 - regularization_loss: 0.0000e+00 - total_loss: 49020.9555\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49016.6366 - regularization_loss: 0.0000e+00 - total_loss: 49016.6366\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49012.3685 - regularization_loss: 0.0000e+00 - total_loss: 49012.3685\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49008.0960 - regularization_loss: 0.0000e+00 - total_loss: 49008.0960\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 49003.8747 - regularization_loss: 0.0000e+00 - total_loss: 49003.8747 - val_factorized_top_k/top_1_categorical_accuracy: 0.0411 - val_factorized_top_k/top_5_categorical_accuracy: 0.1803 - val_factorized_top_k/top_10_categorical_accuracy: 0.2495 - val_factorized_top_k/top_50_categorical_accuracy: 0.4016 - val_factorized_top_k/top_100_categorical_accuracy: 0.4803 - val_loss: 2081.8398 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2081.8398\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48999.6398 - regularization_loss: 0.0000e+00 - total_loss: 48999.6398\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48995.4641 - regularization_loss: 0.0000e+00 - total_loss: 48995.4641\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48991.2634 - regularization_loss: 0.0000e+00 - total_loss: 48991.2634\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48987.1351 - regularization_loss: 0.0000e+00 - total_loss: 48987.1351\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48982.9633 - regularization_loss: 0.0000e+00 - total_loss: 48982.9633 - val_factorized_top_k/top_1_categorical_accuracy: 0.0402 - val_factorized_top_k/top_5_categorical_accuracy: 0.1803 - val_factorized_top_k/top_10_categorical_accuracy: 0.2499 - val_factorized_top_k/top_50_categorical_accuracy: 0.4020 - val_factorized_top_k/top_100_categorical_accuracy: 0.4809 - val_loss: 2080.7913 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2080.7913\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48978.8828 - regularization_loss: 0.0000e+00 - total_loss: 48978.8828\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48974.7507 - regularization_loss: 0.0000e+00 - total_loss: 48974.7507\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48970.7109 - regularization_loss: 0.0000e+00 - total_loss: 48970.7109\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48966.6202 - regularization_loss: 0.0000e+00 - total_loss: 48966.6202\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 94s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48962.6207 - regularization_loss: 0.0000e+00 - total_loss: 48962.6207 - val_factorized_top_k/top_1_categorical_accuracy: 0.0401 - val_factorized_top_k/top_5_categorical_accuracy: 0.1806 - val_factorized_top_k/top_10_categorical_accuracy: 0.2504 - val_factorized_top_k/top_50_categorical_accuracy: 0.4024 - val_factorized_top_k/top_100_categorical_accuracy: 0.4811 - val_loss: 2079.8923 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2079.8923\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48958.5712 - regularization_loss: 0.0000e+00 - total_loss: 48958.5712\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48954.6108 - regularization_loss: 0.0000e+00 - total_loss: 48954.6108\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48950.6024 - regularization_loss: 0.0000e+00 - total_loss: 48950.6024\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48946.6785 - regularization_loss: 0.0000e+00 - total_loss: 48946.6785\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48942.7104 - regularization_loss: 0.0000e+00 - total_loss: 48942.7104 - val_factorized_top_k/top_1_categorical_accuracy: 0.0410 - val_factorized_top_k/top_5_categorical_accuracy: 0.1809 - val_factorized_top_k/top_10_categorical_accuracy: 0.2506 - val_factorized_top_k/top_50_categorical_accuracy: 0.4025 - val_factorized_top_k/top_100_categorical_accuracy: 0.4814 - val_loss: 2078.9236 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2078.9236\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48938.8207 - regularization_loss: 0.0000e+00 - total_loss: 48938.8207\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48934.8912 - regularization_loss: 0.0000e+00 - total_loss: 48934.8912\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48931.0381 - regularization_loss: 0.0000e+00 - total_loss: 48931.0381\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48927.1434 - regularization_loss: 0.0000e+00 - total_loss: 48927.1434\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48923.3250 - regularization_loss: 0.0000e+00 - total_loss: 48923.3250 - val_factorized_top_k/top_1_categorical_accuracy: 0.0403 - val_factorized_top_k/top_5_categorical_accuracy: 0.1812 - val_factorized_top_k/top_10_categorical_accuracy: 0.2508 - val_factorized_top_k/top_50_categorical_accuracy: 0.4033 - val_factorized_top_k/top_100_categorical_accuracy: 0.4817 - val_loss: 2078.0894 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2078.0894\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48919.4658 - regularization_loss: 0.0000e+00 - total_loss: 48919.4658\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48915.6819 - regularization_loss: 0.0000e+00 - total_loss: 48915.6819\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48911.8608 - regularization_loss: 0.0000e+00 - total_loss: 48911.8608\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48908.1103 - regularization_loss: 0.0000e+00 - total_loss: 48908.1103\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48904.3275 - regularization_loss: 0.0000e+00 - total_loss: 48904.3275 - val_factorized_top_k/top_1_categorical_accuracy: 0.0402 - val_factorized_top_k/top_5_categorical_accuracy: 0.1811 - val_factorized_top_k/top_10_categorical_accuracy: 0.2516 - val_factorized_top_k/top_50_categorical_accuracy: 0.4035 - val_factorized_top_k/top_100_categorical_accuracy: 0.4818 - val_loss: 2077.1855 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2077.1855\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48900.6131 - regularization_loss: 0.0000e+00 - total_loss: 48900.6131\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48896.8640 - regularization_loss: 0.0000e+00 - total_loss: 48896.8640\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48893.1852 - regularization_loss: 0.0000e+00 - total_loss: 48893.1852\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48889.4672 - regularization_loss: 0.0000e+00 - total_loss: 48889.4672\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48885.8239 - regularization_loss: 0.0000e+00 - total_loss: 48885.8239 - val_factorized_top_k/top_1_categorical_accuracy: 0.0402 - val_factorized_top_k/top_5_categorical_accuracy: 0.1818 - val_factorized_top_k/top_10_categorical_accuracy: 0.2515 - val_factorized_top_k/top_50_categorical_accuracy: 0.4038 - val_factorized_top_k/top_100_categorical_accuracy: 0.4821 - val_loss: 2076.4043 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2076.4043\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48882.1404 - regularization_loss: 0.0000e+00 - total_loss: 48882.1404\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48878.5305 - regularization_loss: 0.0000e+00 - total_loss: 48878.5305\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48874.8848 - regularization_loss: 0.0000e+00 - total_loss: 48874.8848\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 51s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48871.3075 - regularization_loss: 0.0000e+00 - total_loss: 48871.3075\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48867.6942 - regularization_loss: 0.0000e+00 - total_loss: 48867.6942 - val_factorized_top_k/top_1_categorical_accuracy: 0.0399 - val_factorized_top_k/top_5_categorical_accuracy: 0.1820 - val_factorized_top_k/top_10_categorical_accuracy: 0.2517 - val_factorized_top_k/top_50_categorical_accuracy: 0.4042 - val_factorized_top_k/top_100_categorical_accuracy: 0.4827 - val_loss: 2075.5610 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2075.5610\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48864.1422 - regularization_loss: 0.0000e+00 - total_loss: 48864.1422\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48860.5621 - regularization_loss: 0.0000e+00 - total_loss: 48860.5621\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48857.0346 - regularization_loss: 0.0000e+00 - total_loss: 48857.0346\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48853.4823 - regularization_loss: 0.0000e+00 - total_loss: 48853.4823\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 93s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48849.9829 - regularization_loss: 0.0000e+00 - total_loss: 48849.9829 - val_factorized_top_k/top_1_categorical_accuracy: 0.0398 - val_factorized_top_k/top_5_categorical_accuracy: 0.1819 - val_factorized_top_k/top_10_categorical_accuracy: 0.2519 - val_factorized_top_k/top_50_categorical_accuracy: 0.4046 - val_factorized_top_k/top_100_categorical_accuracy: 0.4828 - val_loss: 2074.8406 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2074.8406\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48846.4591 - regularization_loss: 0.0000e+00 - total_loss: 48846.4591\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48842.9882 - regularization_loss: 0.0000e+00 - total_loss: 48842.9882\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48839.4854 - regularization_loss: 0.0000e+00 - total_loss: 48839.4854\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 50s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48836.0538 - regularization_loss: 0.0000e+00 - total_loss: 48836.0538\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 92s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 48832.5742 - regularization_loss: 0.0000e+00 - total_loss: 48832.5742 - val_factorized_top_k/top_1_categorical_accuracy: 0.0389 - val_factorized_top_k/top_5_categorical_accuracy: 0.1820 - val_factorized_top_k/top_10_categorical_accuracy: 0.2526 - val_factorized_top_k/top_50_categorical_accuracy: 0.4047 - val_factorized_top_k/top_100_categorical_accuracy: 0.4831 - val_loss: 2074.0537 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2074.0537\n",
      "Wall time: 4h 56min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "one_layer_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "308973cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-100 accuracy: 0.48.\n"
     ]
    }
   ],
   "source": [
    "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e09628e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11451.3388671875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_layer_history.history[\"total_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff588f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints_one_layer/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a4f6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-100 accuracy: 0.35.\n"
     ]
    }
   ],
   "source": [
    "model_two_layer = CombinedM  odel([64, 32])\n",
    "model_two_layer.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "two_layer_history = model_two_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "accuracy = two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f3d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two_layer.save_weights('./checkpoints_two_layer/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f4cc48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12874.09375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_layer_history.history[\"total_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76298583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1251037b550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4077dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.History"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(one_layer_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b78741ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../one_layer_history.obj', 'wb') as pickle_file:\n",
    "    pickle.dump(one_layer_history.history, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d97284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three_layer = MovielensModel([128, 64, 32])\n",
    "model_three_layer.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "three_layer_history = model_three_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "accuracy = three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "832bf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../two_layer_history.obj', 'wb') as pickle_file:\n",
    "    pickle.dump(two_layer_history.history, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28e1cfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_layer_history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "plt.plot(epochs, three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"3 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192cd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
