{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60389781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade83d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n",
    "import sampling\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Flatten   # to flatten the input data\n",
    "from tensorflow.keras.layers import Dense     # for the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa97de",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3614e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_SMALL = \"../Data/EDA_files/ratings_small.parquet\"\n",
    "RECIPES_SMALL = \"../Data/EDA_files/recipes_small.parquet\"\n",
    "\n",
    "ING_CLEAN_NO_COMMON = '../Data/cleaned_files/ingredients_clean_without_common_words.obj'\n",
    "KEYWORDS_CLEAN = '../Data/cleaned_files/keywords_cleaned.obj'\n",
    "CATEGORIES_CLEAN = '../Data/cleaned_files/categories_cleaned.obj'\n",
    "NAMES_CLEAN = '../Data/cleaned_files/names_cleaned.obj'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cfafb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa98504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_small = pd.read_parquet(RECIPES_SMALL)\n",
    "ratings_small = pd.read_parquet(RATINGS_SMALL)\n",
    "\n",
    "with open(ING_CLEAN_NO_COMMON, \"rb\") as input_file:\n",
    "    ingredients = pickle.load(input_file)\n",
    "    \n",
    "with open(CATEGORIES_CLEAN, \"rb\") as input_file:\n",
    "    categories = pickle.load(input_file)\n",
    "    \n",
    "with open(NAMES_CLEAN, \"rb\") as input_file:\n",
    "    names = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3a0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1401982 entries, 0 to 1401981\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count    Dtype              \n",
      "---  ------         --------------    -----              \n",
      " 0   RecipeId       1401982 non-null  int32              \n",
      " 1   AuthorId       1401982 non-null  int32              \n",
      " 2   Rating         1401982 non-null  int32              \n",
      " 3   Review         1401982 non-null  object             \n",
      " 4   DateSubmitted  1401982 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int32(3), object(1)\n",
      "memory usage: 37.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_small.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dc5a3",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0d29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_small[\"Timestamp\"] = ratings_small.DateSubmitted.map(lambda x: int(x.timestamp()))\n",
    "ratings_small.drop(columns=[\"Rating\", \"Review\", \"DateSubmitted\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02782af",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_min_20 = sampling.get_rating_with_min_number(ratings_small, 20, col_name='AuthorId')\n",
    "recipe_min_20 = sampling.get_rating_with_min_number(ratings_small, 10, col_name='RecipeId')\n",
    "\n",
    "ratings_min_20 = author_min_20.merge(recipe_min_20, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ae9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sample = ratings_min_20.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bf20ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            780\n",
       "1           4366\n",
       "2           4807\n",
       "3            810\n",
       "4           5466\n",
       "           ...  \n",
       "441660     49088\n",
       "441661     43023\n",
       "441662     73866\n",
       "441663     26370\n",
       "441664    339905\n",
       "Name: RecipeId, Length: 441665, dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_sample.RecipeId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b70ec",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ab7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset = recipes_small[[\"RecipeId\"]].merge(ingredients, on=\"RecipeId\", how=\"inner\").merge(categories, on=\"RecipeId\",\n",
    "                                                                                                 how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaba39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset[\"Ingredients\"] = recipes_subset[\"Ingredients\"].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ed74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = ratings_sample.merge(recipes_subset, on=\"RecipeId\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed0f2e",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6cac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.AuthorId = merged_dataset.AuthorId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "merged_dataset.RecipeId = merged_dataset.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "\n",
    "ratings_dict = merged_dataset[['AuthorId', 'RecipeId', 'Timestamp', \"Ingredients\", \"RecipeCategory\"]]\n",
    "ratings_dict = {name: np.array(value) for name, value in ratings_dict.items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings_dict)\n",
    "\n",
    "\n",
    "ratings = ratings.map(lambda x: {'AuthorId' : x['AuthorId'], \n",
    "                                 'RecipeId' : x['RecipeId'],\n",
    "                                 'Timestamp' : x['Timestamp'],\n",
    "                                 'Ingredients' : x['Ingredients'], \n",
    "                                 'RecipeCategory': x['RecipeCategory']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a46bb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AuthorId': b'2312',\n",
      " 'Ingredients': b'cayenne pepper chicken breast cumin garlic ginger lemon lemo'\n",
      "                b'n juice nutmeg paprika turmeric water',\n",
      " 'RecipeCategory': b'chicken breast',\n",
      " 'RecipeId': b'780',\n",
      " 'Timestamp': 968798976}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d705a15",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730beda7",
   "metadata": {},
   "source": [
    "## Creating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d1d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_ids_lookup = tf.keras.layers.StringLookup()\n",
    "# recipe_ids_lookup.adapt(ratings.map(lambda x: x[\"RecipeId\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d35f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Vocabulary: {recipe_ids_lookup.get_vocabulary()[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a13318",
   "metadata": {},
   "source": [
    "## Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7131b0a",
   "metadata": {},
   "source": [
    "### Recipe id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c35e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_id_embedding = tf.keras.layers.Embedding(\n",
    "#                         input_dim=recipe_ids_lookup.vocabulary_size(),\n",
    "#                         output_dim=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c73e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_id_model = tf.keras.Sequential([recipe_ids_lookup, recipe_id_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2fb6a8",
   "metadata": {},
   "source": [
    "### User id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab54a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id_lookup = tf.keras.layers.StringLookup()\n",
    "# user_id_lookup.adapt(ratings.map(lambda x: x[\"AuthorId\"]))\n",
    "\n",
    "# user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocab_size(), 32)\n",
    "# user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db6c43",
   "metadata": {},
   "source": [
    "## Normalizing timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "175ed6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in ratings.take(3).as_numpy_iterator():\n",
    "#     print(f\"Timestamp: {x['Timestamp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94eb50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_normalization = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "# timestamp_normalization.adapt(ratings.map(lambda x: x['Timestamp']).batch(1024))\n",
    "\n",
    "# for x in ratings.take(3).as_numpy_iterator():\n",
    "#     print(f\"Normalized timestamp: {timestamp_normalization(x['Timestamp'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc849a7",
   "metadata": {},
   "source": [
    "## Discretization timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8ba00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"Timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b92ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933e5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_embedding_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "#     tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32)\n",
    "# ])\n",
    "\n",
    "# for timestamp in ratings.take(1).map(lambda x: x[\"Timestamp\"]).batch(1).as_numpy_iterator():\n",
    "#     print(f\"Timestamp embedding: {timestamp_embedding_model(timestamp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a0a6a",
   "metadata": {},
   "source": [
    "## Processing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4aa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_text = tf.keras.layers.TextVectorization()\n",
    "# title_text.adapt(recipes.map(lambda x: x['Name']).batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6dd4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in recipes.take(1).map(lambda x: x['Name']).batch(1).as_numpy_iterator():\n",
    "#     print(title_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "048b3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_text.get_vocabulary()[705] + \" \" + title_text.get_vocabulary()[2] + \" \" + title_text.get_vocabulary()[60] + \" \" + title_text.get_vocabulary()[433] + \" \" + title_text.get_vocabulary()[831]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f35af9",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "786c7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(lambda x: x[\"AuthorId\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e56ef819",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recipes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UYTKOW~1\\AppData\\Local\\Temp/ipykernel_13608/3180409175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munique_recipe_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1_000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'recipes' is not defined"
     ]
    }
   ],
   "source": [
    "unique_recipe_names = np.unique(np.concatenate(list(recipes.batch(1_000).map(lambda x: x[\"Name\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_recipe_ids = np.unique(np.concatenate(list(recipes.batch(1_000).map(lambda x: x[\"RecipeId\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ec86a",
   "metadata": {},
   "source": [
    "## User model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, verbose=False):\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "        if(self._verbose):\n",
    "            print(\"USER MODEL INIT\")\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.timestamp_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32),\n",
    "        ])\n",
    "        \n",
    "        self.normalized_timestamp = tf.keras.layers.Normalization(axis=None)\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"User model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"AuthorId\"]),\n",
    "            self.timestamp_embedding(inputs[\"Timestamp\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"Timestamp\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = UserModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Representation: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651cbe96",
   "metadata": {},
   "source": [
    "## Recipe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, verbose=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "        self._verbose = verbose\n",
    "        if(verbose):\n",
    "            print(\"RECIPE MODEL INIT\")\n",
    "        self.recipe_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_recipe_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_recipe_ids)+1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.name_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        \n",
    "        self.name_text_embedding = tf.keras.Sequential([\n",
    "            self.name_vectorizer,\n",
    "            tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.name_vectorizer.adapt(recipes.map(lambda x: x['Name']))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Recipe model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "        return tf.concat([\n",
    "            self.recipe_id_embedding(inputs[\"RecipeId\"]),\n",
    "            self.name_text_embedding(inputs[\"Name\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c73ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_model = RecipeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in recipes.take(1).as_numpy_iterator():\n",
    "# #     print(x)\n",
    "#     print(recipe_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355d301",
   "metadata": {},
   "source": [
    "## Query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "        Args:\n",
    "            layer_sizes:\n",
    "        A list of integers where the i-th entry represents the number of units\n",
    "        the i-th layer contains.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Query model init\")\n",
    "            \n",
    "        self._verbose = verbose\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Query model call\")\n",
    "            print(\"Input: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35017010",
   "metadata": {},
   "source": [
    "## Candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73731716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding movies.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        \"\"\"Model for encoding movies.\n",
    "\n",
    "        Args:\n",
    "          layer_sizes:\n",
    "            A list of integers where the i-th entry represents the number of units\n",
    "            the i-th layer contains.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print(\"Candidate model init\")\n",
    "        self.embedding_model = RecipeModel()\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "        self._verbose = verbose\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Candidate model call\")\n",
    "            print(\"Inputs: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66782c19",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, layer_sizes, verbose=False):\n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print(\"Init combined model\")\n",
    "        self.query_model = QueryModel(layer_sizes)\n",
    "        self.candidate_model = CandidateModel(layer_sizes)\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=recipes.batch(128).map(self.candidate_model),\n",
    "            ),\n",
    "        )\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, features, training=False):\n",
    "        if(self._verbose):\n",
    "            print(\"Combined model compute loss\")\n",
    "            print(\"Features: \", features)\n",
    "        query_embeddings = self.query_model({\n",
    "            \"AuthorId\": features[\"AuthorId\"],\n",
    "            \"Timestamp\": features[\"Timestamp\"],\n",
    "        })\n",
    "        \n",
    "        recipe_embeddings = self.candidate_model({\n",
    "            \"RecipeId\": features[\"RecipeId\"],\n",
    "            \"Name\": features[\"Name\"]\n",
    "        })\n",
    "        \n",
    "        return self.task(\n",
    "            query_embeddings, recipe_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134118",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ratings_min_20.shape[0]\n",
    "train_size = int(0.8 * size)\n",
    "test_size = size - train_size\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings_merged.shuffle(size, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.take(train_size).take(test_size)\n",
    "\n",
    "cached_train = train.shuffle(1_000_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e50d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "model = CombinedModel([32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.query_model.dense_layers.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "one_layer_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_history.history[\"total_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff588f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints_one_layer/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two_layer = CombinedM  odel([64, 32])\n",
    "model_two_layer.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "two_layer_history = model_two_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "accuracy = two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two_layer.save_weights('./checkpoints_two_layer/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4cc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_history.history[\"total_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76298583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(one_layer_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78741ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../one_layer_history.obj', 'wb') as pickle_file:\n",
    "    pickle.dump(one_layer_history.history, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d97284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three_layer = MovielensModel([128, 64, 32])\n",
    "model_three_layer.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "three_layer_history = model_three_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "accuracy = three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../two_layer_history.obj', 'wb') as pickle_file:\n",
    "    pickle.dump(two_layer_history.history, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "plt.plot(epochs, three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"3 layers\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192cd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
