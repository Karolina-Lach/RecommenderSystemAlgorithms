{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ae0d97",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af7eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n",
    "import sampling\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Flatten   \n",
    "from tensorflow.keras.layers import Dense     \n",
    "\n",
    "import TensorflowRichFeatures as tfrs_rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ed952",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef055b",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_BASE = \"../Data/base/ratings_base.parquet\"\n",
    "RECIPES_BASE = \"../Data/base/recipes_base.parquet\"\n",
    "\n",
    "INGREDIENTS_CLEAN = '../Data/cleaned_files/ingredients_clean_without_common_words.obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4882294",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a8037dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_small = pd.read_parquet(RECIPES_BASE)\n",
    "ratings_small = pd.read_parquet(RATINGS_BASE)\n",
    "\n",
    "with open(INGREDIENTS_CLEAN, \"rb\") as input_file:\n",
    "    ingredients_clean = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7adc74c",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c1ea613",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sample = sampling.get_ratings_with_min_number_list(ratings_small, [20,20])\n",
    "recipe_ids_in_sample = list(set(ratings_sample.RecipeId))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d809b",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be3501b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset = recipes_small[[\"RecipeId\"]].merge(ingredients_clean, on=\"RecipeId\", how=\"inner\")\n",
    "recipes_subset[\"Ingredients\"] = recipes_subset[\"Ingredients\"].map(lambda x: \" \".join(x))\n",
    "recipes_subset = recipes_subset[recipes_subset.RecipeId.isin(recipe_ids_in_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c898424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = ratings_sample.merge(recipes_subset, on=\"RecipeId\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db31d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.drop(columns=[\"DateSubmitted\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "043e3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4807</td>\n",
       "      <td>2695</td>\n",
       "      <td>2</td>\n",
       "      <td>butter turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4807</td>\n",
       "      <td>74652</td>\n",
       "      <td>5</td>\n",
       "      <td>butter turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4807</td>\n",
       "      <td>73272</td>\n",
       "      <td>5</td>\n",
       "      <td>butter turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4807</td>\n",
       "      <td>111526</td>\n",
       "      <td>5</td>\n",
       "      <td>butter turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4807</td>\n",
       "      <td>128803</td>\n",
       "      <td>5</td>\n",
       "      <td>butter turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310017</th>\n",
       "      <td>58901</td>\n",
       "      <td>582561</td>\n",
       "      <td>5</td>\n",
       "      <td>bay beef broth beef meat celery rib corn garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310018</th>\n",
       "      <td>519642</td>\n",
       "      <td>182312</td>\n",
       "      <td>4</td>\n",
       "      <td>brown sugar butter cinnamon egg honey milk pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310019</th>\n",
       "      <td>533699</td>\n",
       "      <td>109030</td>\n",
       "      <td>5</td>\n",
       "      <td>italian sausage mozzarella cheese parmesan che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310020</th>\n",
       "      <td>500502</td>\n",
       "      <td>53859</td>\n",
       "      <td>4</td>\n",
       "      <td>butter coconut oil egg flour milk soda sugar v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310021</th>\n",
       "      <td>192346</td>\n",
       "      <td>2001112113</td>\n",
       "      <td>5</td>\n",
       "      <td>brewer yeast brown sugar butter chocolate chip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310022 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecipeId    AuthorId  Rating  \\\n",
       "0           4807        2695       2   \n",
       "1           4807       74652       5   \n",
       "2           4807       73272       5   \n",
       "3           4807      111526       5   \n",
       "4           4807      128803       5   \n",
       "...          ...         ...     ...   \n",
       "310017     58901      582561       5   \n",
       "310018    519642      182312       4   \n",
       "310019    533699      109030       5   \n",
       "310020    500502       53859       4   \n",
       "310021    192346  2001112113       5   \n",
       "\n",
       "                                              Ingredients  \n",
       "0                                           butter turkey  \n",
       "1                                           butter turkey  \n",
       "2                                           butter turkey  \n",
       "3                                           butter turkey  \n",
       "4                                           butter turkey  \n",
       "...                                                   ...  \n",
       "310017  bay beef broth beef meat celery rib corn garli...  \n",
       "310018  brown sugar butter cinnamon egg honey milk pow...  \n",
       "310019  italian sausage mozzarella cheese parmesan che...  \n",
       "310020  butter coconut oil egg flour milk soda sugar v...  \n",
       "310021  brewer yeast brown sugar butter chocolate chip...  \n",
       "\n",
       "[310022 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae7682",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f1231",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e5ac63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_subset.RecipeId = recipes_subset.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "\n",
    "recipes_dict = recipes_subset[['RecipeId','Ingredients']]\n",
    "recipes_dict = {name: np.array(value) for name, value in recipes_dict.items()}\n",
    "recipes = tf.data.Dataset.from_tensor_slices(recipes_dict)\n",
    "\n",
    "\n",
    "recipes = recipes.map(lambda x: {'RecipeId' : x['RecipeId'],\n",
    "                                 'Ingredients' : x['Ingredients']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97dca5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ingredients': b'black pepper butter button mushroom celery chicken flour mil'\n",
      "                b'k parsley pepper pimiento worcestershire sauce',\n",
      " 'RecipeId': b'44.0'}\n"
     ]
    }
   ],
   "source": [
    "for x in recipes.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc7a92",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d123c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sample.AuthorId = ratings_sample.AuthorId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "ratings_sample.RecipeId = ratings_sample.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "\n",
    "ratings_dict = ratings_sample.groupby(['AuthorId', 'RecipeId'])['Rating'].sum().reset_index()\n",
    "ratings_dict = {name: np.array(value) for name, value in ratings_dict.items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings_dict)\n",
    "\n",
    "\n",
    "ratings = ratings.map(lambda x: {'AuthorId' : x['AuthorId'], \n",
    "                                 'RecipeId' : x['RecipeId'],\n",
    "                                 'Rating' : x['Rating']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fc14994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AuthorId': b'100026', 'Rating': 5, 'RecipeId': b'120914'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01506e4",
   "metadata": {},
   "source": [
    "## Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e00a4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.AuthorId = merged_dataset.AuthorId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "merged_dataset.RecipeId = merged_dataset.RecipeId.map(lambda x: bytes(str(x), 'utf-8'))\n",
    "\n",
    "merged_dict = merged_dataset[['AuthorId', 'RecipeId', 'Rating', 'Ingredients']]\n",
    "merged_dict = {name: np.array(value) for name, value in merged_dict.items()}\n",
    "merged_dataset = tf.data.Dataset.from_tensor_slices(merged_dict)\n",
    "\n",
    "\n",
    "merged_dataset = merged_dataset.map(lambda x: {'AuthorId' : x['AuthorId'], \n",
    "                                 'RecipeId' : x['RecipeId'],\n",
    "                                 'Ingredients' : x['Ingredients'],\n",
    "                                    'Rating': x['Rating']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf0cac",
   "metadata": {},
   "source": [
    "## Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "277f6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps = np.concatenate(list(ratings.map(lambda x: x[\"Timestamp\"]).batch(100)))\n",
    "\n",
    "# max_timestamp = timestamps.max()\n",
    "# min_timestamp = timestamps.min()\n",
    "\n",
    "# timestamp_buckets = np.linspace(\n",
    "#     min_timestamp, max_timestamp, num=1000,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bd6fd",
   "metadata": {},
   "source": [
    "## Train, test, val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb0bd813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 217015\n",
      "Test size: 46504\n",
      "Val size: 46503\n"
     ]
    }
   ],
   "source": [
    "size = ratings_sample.shape[0]\n",
    "train_size = int(0.7 * size)\n",
    "val_size = int(0.15 * size)\n",
    "test_size = size - train_size - val_size\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = merged_dataset.shuffle(size, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "val = shuffled.take(train_size).take(val_size)\n",
    "test = shuffled.take(train_size).take(val_size).take(test_size)\n",
    "\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "print(f\"Val size: {val_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82a77465",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ids = merged_dataset.batch(1_000_000).map(lambda x: x['RecipeId'])\n",
    "user_ids = merged_dataset.batch(1_000_000).map(lambda x: x[\"AuthorId\"])\n",
    "\n",
    "unique_recipe_ids = np.unique(np.concatenate(list(recipe_ids)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61f3b5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b81ccb",
   "metadata": {},
   "source": [
    "## Query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8263106b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_1568/1127978980.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\UYTKOW~1\\AppData\\Local\\Temp/ipykernel_1568/1127978980.py\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    print(\"AuthorId\": inputs[\"AuthorId\"])\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class UserModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 unique_user_ids,\n",
    "                 verbose=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "        if(self._verbose):\n",
    "            print(\"USER MODEL INIT\")\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32)\n",
    "        ])\n",
    "        \n",
    "#         self.timestamp_embedding = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "#             tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32),\n",
    "#         ])\n",
    "        \n",
    "#         self.normalized_timestamp = tf.keras.layers.Normalization(axis=None)\n",
    "#         self.normalized_timestamp.adapt(timestamps)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"User model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "            print(\"AuthorId\": inputs[\"AuthorId\"])\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"AuthorId\"]),\n",
    "#             self.timestamp_embedding(inputs[\"Timestamp\"]),\n",
    "#             tf.reshape(self.normalized_timestamp(inputs[\"Timestamp\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9538599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "    def __init__(self, \n",
    "                 layer_sizes,\n",
    "                 unique_user_ids,\n",
    "                 verbose=False):\n",
    "        \"\"\"Model for encoding user queries.\n",
    "        Args:\n",
    "            layer_sizes:\n",
    "        A list of integers where the i-th entry represents the number of units\n",
    "        the i-th layer contains.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        if(verbose):\n",
    "            print(\"Query model init\")\n",
    "            \n",
    "        self._verbose = verbose\n",
    "        # We first use the user model for generating embeddings.\n",
    "        self.embedding_model = UserModel(unique_user_ids, verbose)\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Query model call\")\n",
    "            print(\"Input: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b07ee3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation: [-0.01153687  0.02530286  0.04176519]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel(unique_user_ids)\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Representation: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13e943",
   "metadata": {},
   "source": [
    "## Candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eee83432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 unique_recipe_ids,\n",
    "                 recipes_dataset,\n",
    "                 verbose=False):\n",
    "        super().__init__()\n",
    "        max_tokens = 10_000\n",
    "        embedding_dim=32\n",
    "        \n",
    "        self._verbose = verbose\n",
    "        if(verbose):\n",
    "            print(\"RECIPE MODEL INIT\")\n",
    "        self.recipe_id_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_recipe_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_recipe_ids)+1, 32)\n",
    "        ])\n",
    "        \n",
    "        self.ingredients_vectorizer = tf.keras.layers.TextVectorization(max_tokens = max_tokens)\n",
    "        \n",
    "        self.ingredients_text_embedding = tf.keras.Sequential([\n",
    "            self.ingredients_vectorizer,\n",
    "            tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        self.ingredients_vectorizer.adapt(recipes_dataset.map(lambda x: x['Ingredients']))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Recipe model call\")\n",
    "            print(\"INPUTS: \", inputs)\n",
    "        return tf.concat([\n",
    "            self.recipe_id_embedding(inputs[\"RecipeId\"]),\n",
    "            self.ingredients_text_embedding(inputs[\"Ingredients\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d983a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding recipes.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 layer_sizes, \n",
    "                 unique_recipe_ids,\n",
    "                 recipes_dataset,\n",
    "                 verbose=False):\n",
    "\n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print(\"Candidate model init\")\n",
    "        self.embedding_model = RecipeModel(unique_recipe_ids,\n",
    "                                           recipes_dataset,\n",
    "                                           verbose)\n",
    "\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        # No activation for the last layer.\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "            \n",
    "        self._verbose = verbose\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        if(self._verbose):\n",
    "            print(\"Candidate model call\")\n",
    "            print(\"Inputs: \", inputs)\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081efb6",
   "metadata": {},
   "source": [
    "## Ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79bb60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, layer_sizes,\n",
    "                 unique_user_ids, \n",
    "                 unique_recipe_ids, \n",
    "                 embedding_dimension, \n",
    "                 recipes_dataset,\n",
    "                 verbose=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        if(verbose):\n",
    "            print('Ranking model INIT')\n",
    "        \n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.query_model = QueryModel(layer_sizes,\n",
    "                                          unique_user_ids,\n",
    "                                          verbose=verbose)\n",
    "        \n",
    "        self.candidate_model = CandidateModel(layer_sizes, \n",
    "                                                unique_recipe_ids,\n",
    "                                                recipes_dataset,\n",
    "                                                verbose=verbose)\n",
    "        \n",
    "        # Compute predictions\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.verbose:\n",
    "            print('Ranking model CALL')\n",
    "            print('INPUTS', inputs)\n",
    "            \n",
    "        user_id, recipe_id, ingredients = inputs\n",
    "        \n",
    "        user_embedding = self.query_model({\n",
    "            \"AuthorId\": user_id\n",
    "        })\n",
    "        \n",
    "        recipe_embedding = self.candidate_model({\n",
    "            \"RecipeId\": recipe_id,\n",
    "            \"Ingredients\": ingredients\n",
    "        })\n",
    "        \n",
    "        return self.ratings(tf.concat([user_embedding, recipe_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61bd79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRankingModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, layer_sizes,\n",
    "                 unique_user_ids, \n",
    "                 unique_recipe_ids, \n",
    "                 embedding_dimension, \n",
    "                 recipes_dataset,\n",
    "                 verbose=False):\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "        self.ranking_model: tf.keras.Model = RankingModel(layer_sizes, unique_user_ids, unique_recipe_ids, embedding_dimension, recipes_dataset, verbose)\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
    "            \n",
    "        \n",
    "    def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "        if self._verbose:\n",
    "            print('RECIPE RANKING MODEL CALL')\n",
    "            \n",
    "        return self.ranking_model((features[\"AuthorId\"], features[\"RecipeId\"], features[\"Ingredients\"]))\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        if self._verbose:\n",
    "             print('COMPUTE LOSS ', features)\n",
    "        labels = features.pop(\"Rating\")\n",
    "        rating_predictions = self(features)\n",
    "        \n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab8aeea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking model INIT\n",
      "Query model init\n",
      "USER MODEL INIT\n",
      "Candidate model init\n",
      "RECIPE MODEL INIT\n"
     ]
    }
   ],
   "source": [
    "model_1 = RecipeRankingModel([32], unique_user_ids=unique_user_ids,\n",
    "                            unique_recipe_ids=unique_recipe_ids,\n",
    "                            embedding_dimension=32,\n",
    "                            recipes_dataset=recipes,\n",
    "                            verbose=True)\n",
    "model_1.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "23f51f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(250_000).batch(16384).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "cached_val = val.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "886f4646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: {AuthorId: (None,), RecipeId: (None,), Ingredients: (None,), Rating: (None,)}, types: {AuthorId: tf.string, RecipeId: tf.string, Ingredients: tf.string, Rating: tf.int32}>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edb84e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "COMPUTE LOSS  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Rating': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}\n",
      "RECIPE RANKING MODEL CALL\n",
      "Ranking model CALL\n",
      "INPUTS (<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)\n",
      "Query model call\n",
      "Input:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "User model call\n",
      "INPUTS:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Candidate model call\n",
      "Inputs:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "Recipe model call\n",
      "INPUTS:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "COMPUTE LOSS  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Rating': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}\n",
      "RECIPE RANKING MODEL CALL\n",
      "Ranking model CALL\n",
      "INPUTS (<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)\n",
      "Query model call\n",
      "Input:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "User model call\n",
      "INPUTS:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Candidate model call\n",
      "Inputs:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "Recipe model call\n",
      "INPUTS:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "14/14 [==============================] - 10s 537ms/step - root_mean_squared_error: 4.7786 - loss: 20.2781 - regularization_loss: 0.0000e+00 - total_loss: 20.2781\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 6s 433ms/step - root_mean_squared_error: 0.9604 - loss: 0.9304 - regularization_loss: 0.0000e+00 - total_loss: 0.9304\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 6s 434ms/step - root_mean_squared_error: 0.9377 - loss: 0.8841 - regularization_loss: 0.0000e+00 - total_loss: 0.8841\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 6s 433ms/step - root_mean_squared_error: 0.9210 - loss: 0.8540 - regularization_loss: 0.0000e+00 - total_loss: 0.8540\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - ETA: 0s - root_mean_squared_error: 0.9156 - loss: 0.8409 - regularization_loss: 0.0000e+00 - total_loss: 0.8409COMPUTE LOSS  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Rating': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}\n",
      "RECIPE RANKING MODEL CALL\n",
      "Ranking model CALL\n",
      "INPUTS (<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)\n",
      "Query model call\n",
      "Input:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "User model call\n",
      "INPUTS:  {'AuthorId': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Candidate model call\n",
      "Inputs:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "Recipe model call\n",
      "INPUTS:  {'RecipeId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'Ingredients': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>}\n",
      "14/14 [==============================] - 8s 617ms/step - root_mean_squared_error: 0.9156 - loss: 0.8440 - regularization_loss: 0.0000e+00 - total_loss: 0.8440 - val_root_mean_squared_error: 0.9136 - val_loss: 1.0444 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0444\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_1_history = model_1.fit(cached_train,\n",
    "                              epochs=5, \n",
    "                              verbose=1,\n",
    "                              validation_data=cached_val,\n",
    "                              validation_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
